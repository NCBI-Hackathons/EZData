#!/usr/bin/env python3

import argparse
import SRA_Tinder
import concurrent.futures
import multiprocessing  

from SRA_Tinder import sra_tinder
from SRA_Tinder.sra_stream import SRA_Stream
from functools import partial

import SRA_Tinder.trimandcount as trimandcount
import subprocess
import sys
import os
import pandas
import asyncio


def generate_acc_statistics(fastqfile):
    '''
    Generates statistics from a fastq file generated from
    an SRA accession

    Parameters
    ----------
    fastqfile : str (pathlike)
        A path the the raw FASTQ file

    Returns
    -------
    a pandas dataframe containing statistcs

    '''
    print(f'Generating stats for {fastqfile}')
    titleline = [
        "Accession", "mean_quality_score", "most_abundent_organism",
        "percent_abundence", "number_of_organims_greater_than_1%_abundence",
        "total_reads_checked", "total_reads_withadapter", "mean_readlen_before_trim", "std_readlen_before_trim",
        "mean_readlen_of_trimmed_reads", "std_readlen_of_trimmed_reads"
    ]
    final_output_line = []
    accession = fastqfile.replace('.fastq','')
    url = "https://trace.ncbi.nlm.nih.gov/Traces/sra/?run={}".format(accession)
    # Get some data about the SRA ACC from the web
    my_tinder = sra_tinder.sra_tinder_web(accession)
    run_info = my_tinder.scrape_run()
    m = {True: 'Pass', False: 'Fail'}
    if args.full:
        final_output_line += [accession, run_info['study'], run_info['%q30'], m[(run_info['%q30']>70)], run_info['mean_qual'], run_info['top_org'], run_info['top_org_%'], run_info['#_1%_orgs'], run_info['source'], run_info['strategy'], run_info['selection'], run_info['layout'], url]
    else:
        final_output_line += [run_info['%q30'], m[(run_info['%q30']>70)], run_info['top_org'], run_info['top_org_%'], run_info['#_1%_orgs'], run_info['source']]
    # Get some data from trimmed data
    totalreads, withadapter, mean_readlen, \
    std_readlen, readlen_trimmed, \
    std_readlen_trimmed = trimandcount.basesleftaftertriming(fastqfile)
    # Generate a list of the info
    final_output_line += [totalreads, withadapter, mean_readlen, std_readlen, readlen_trimmed, std_readlen_trimmed]
    # Generate the resultant Pandas frame and create output
    final_output_line = [str(x) for x in final_output_line]
    df = pandas.DataFrame.from_records(final_output_line, columns=titleline)
    return final_output_line

# Event Loops
def run_matching_event_loop(args):
    """
    :param args:
    :return:
    """
    streamer = SRA_Stream()
    loop = asyncio.get_event_loop()
    pool = concurrent.futures.ProcessPoolExecutor(max_workers=100)
    # Create a task list
    tasks = []
    streamer = SRA_Stream()
    # Process Input File
    with open(args.input) as IN:
        for acc in IN:
            # Each line is an SRR accession
            acc = acc.strip()
            # Create a condition
            event = asyncio.Event()
            # Create a task for streaming
            stream = streamer.stream(acc,event)
            pipe_path = streamer.get_pipe(acc)
            stats = generate_acc_statistics(pipe_path,event)
            # Append tasks
            tasks.append(stream)
            tasks.append(stats)
    results = asyncio.gather(*tasks)
    loop.run_until_complete(results)
    return results

def run_stream_event_loop(args):
    loop = asyncio.get_event_loop() 
    streamer = SRA_Stream()
    tasks = []
    accs = [acc.strip() for acc in open(args.input)]
    pool = concurrent.futures.ProcessPoolExecutor(max_workers=100)
    for acc in accs:
        tasks.append(streamer.stream(acc,pool=pool))
    results = asyncio.gather(*tasks)
    loop.run_until_complete(results)
    return results
            


# Main logic to parse args and run the correct event loop
if __name__ == '__main__':
    parser = argparse.ArgumentParser(
        description=(
            "Find hot datasets in your area (of research)!"    
        ),        
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="\n".join([
            f'version: {SRA_Tinder.__version__}',
            f'install path: {__file__}'
        ])    
    )
    parser.set_defaults(func=lambda x: parser.print_help())
    subparsers = parser.add_subparsers(
        title='Command Line Programs',
        metavar="Available Commands",
        description='Use --help with each command for more info'
    )

    # --------------------------------------------------------------
    # Streaming function -- 
    # Open a bunch of streamin pipes to SRA files
    stream = subparsers.add_parser(
        'stream',
        help='Stream SRA FASTQ files into named pipes'
    )
    stream.add_argument(
        '--input',
        help='input file, one SRR per line'
    )
    stream.set_defaults(func=run_stream_event_loop)

    # --------------------------------------------------------------
    # Matching function
    matches = subparsers.add_parser(
        'match',
        help='create SRA matches'
    )
    matches.add_argument(
        '--input',
        help='input file'
    )
    matches.add_argument(
        '-o',
        help='output file'
    )
    matches.add_argument(
        '--full',
        help='output LOTS of data - can be overwhelming if you are new to this'
    )
    matches.set_defaults(func=run_matching_event_loop)
    
    # Parse and run
    args = parser.parse_args()
    try:
        args.func(args)    
    except Exception as e:
        print(e)
        raise(e)



