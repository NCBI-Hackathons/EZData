#!/usr/bin/env python3

import argparse
import SRA_Tinder
import concurrent.futures

from SRA_Tinder import sra_tinder
from SRA_Tinder.sra_stream import SRA_Stream

import SRA_Tinder.trimandcount as trimandcount
import subprocess
import sys
import pandas
import asyncio


def generate_acc_statistics(fastqfile):
    '''
    Generates statistics from a fastq file generated from
    an SRA accession

    Parameters
    ----------
    fastqfile : str (pathlike)
        A path the the raw FASTQ file

    Returns
    -------
    a pd dataframe containing statistcs

    '''
    print(f'Generating stats for {fastqfile}')
    titleline = [
        "Accession", "mean_quality_score", "most_abundent_organism",
        "percent_abundence", "number_of_organims_greater_than_1%_abundence",
        "total_reads_checked", "total_reads_withadapter", "mean_readlen_before_trim", "std_readlen_before_trim",
        "mean_readlen_of_trimmed_reads", "std_readlen_of_trimmed_reads"
    ]
    final_output_line = []
    accession = fastqfile.replace('.fastq','')
    url = "https://trace.ncbi.nlm.nih.gov/Traces/sra/?run={}".format(accession)
    # Get some data about the SRA ACC from the web
    my_tinder = sra_tinder.sra_tinder_web(accession)
    run_info = my_tinder.scrape_run()
    org_info = my_tinder.scrape_organisms()
    m = {True: 'Pass', False: 'Fail'}
    if args.full:
        final_output_line += [accession, run_info['study'], run_info['%q30'], m[(run_info['%q30']>70)], run_info['mean_qual'], org_info['top_org'], org_info['top_org_%'], org_info['#_1%_orgs'], run_info['source'], run_info['strategy'], run_info['selection'], run_info['layout'], url]
    else:
        final_output_line += [run_info['%q30'], m[(run_info['%q30']>70)], org_info['top_org'], org_info['top_org_%'], org_info['#_1%_orgs'], run_info['source']]
    # Get some data from trimmed data
    totalreads, withadapter, mean_readlen, \
    std_readlen, readlen_trimmed, \
    std_readlen_trimmed = trimandcount.basesleftaftertriming(fastqfile)
    # Generate a list of the info
    final_output_line += [totalreads, withadapter, mean_readlen, std_readlen, readlen_trimmed, std_readlen_trimmed]
    # Generate the resultant Pandas frame and create output
    final_output_line = [str(x) for x in final_output_line]
    df = pandas.DataFrame.from_records(final_output_line, columns=titleline)
    return final_output_line

# Event Loops
def run_matching_event_loop(args):
    """

    :param args:
    :return:
    """
    streamer = SRA_Stream()
    loop = asyncio.get_event_loop()
    # Create a process pool
    pool = concurrent.futures.ProcessPoolExecutor(max_workers=4)
    # Create a task list
    tasks = []
    # Process Input File
    with open(args.input) as IN:
        for acc in IN:
            # Each line is an SRR accession
            acc = acc.strip()
            # Create a task for streaming
            future = streamer.stream(acc,pool=pool)
            tasks.append(future)
            # Create a task for doing stats
            pipe_path = streamer.get_pipe(acc)
            future = loop.run_in_executor(pool, generate_acc_statistics, pipe_path)
            tasks.append(future)
    results = asyncio.gather(*tasks)
    loop.run_until_complete(results)
    return results


if __name__ == '__main__':
    parser = argparse.ArgumentParser(
        description=(
            "Find hot datasets in your area (of research)!"    
        ),        
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="\n".join([
            f'version: {SRA_Tinder.__version__}' 
        ])    
    )
    parser.set_defaults(func=lambda x: parser.print_help())
    subparsers = parser.add_subparsers(
        title='Command Line Programs',
        metavar="Available Commands",
        description='Use --help with each command for more info'
    )

    # basic functions go here
    matches = subparsers.add_parser(
        'match',
        help='create SRA matches'
    )
    matches.add_argument(
        '--input',
        help='input file'
    )
    matches.add_argument(
        '-o',
        help='output file'
    )
    matches.add_argument(
        '--full',
        help='output LOTS of data - can be overwhelming if you are new to this'
    )

    matches.set_defaults(func=run_matching_event_loop)

    args = parser.parse_args()
    try:
        args.func(args)    
    except Exception as e:
        print(e)
        raise(e)



